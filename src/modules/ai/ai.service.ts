import { Inject, Injectable } from '@nestjs/common';
import { ChatOpenAI } from '@langchain/openai';
import {
  HumanMessage,
  AIMessage,
  SystemMessage,
} from '@langchain/core/messages';
import { StringOutputParser } from '@langchain/core/output_parsers';
import { ChatPromptTemplate } from '@langchain/core/prompts';
import { VectorService } from './vector.service';
import { WINSTON_MODULE_NEST_PROVIDER } from 'nest-winston';
import { MessageEntiry } from '../conversation/entiry';
type Message = HumanMessage | AIMessage | SystemMessage;

@Injectable()
export class AiService {
  @Inject(WINSTON_MODULE_NEST_PROVIDER)
  private readonly logger;
  private globalChatModel: ChatOpenAI;
  private ragChatModel: ChatOpenAI;
  private outputParser: StringOutputParser;

  constructor(private readonly vectorService: VectorService) {
    // åˆå§‹åŒ–å…¨ç½‘å¯¹è¯æ¨¡å‹
    this.globalChatModel = new ChatOpenAI({
      openAIApiKey: process.env.OPENAI_API_KEY,
      configuration: {
        baseURL: 'https://api.siliconflow.cn/v1',
      },
      modelName: 'deepseek-ai/DeepSeek-R1',
    });

    // åˆå§‹åŒ–RAGå¯¹è¯æ¨¡å‹
    this.ragChatModel = new ChatOpenAI({
      openAIApiKey: process.env.OPENAI_API_KEY,
      configuration: {
        baseURL: 'https://api.siliconflow.cn/v1',
      },
      model: 'deepseek-ai/DeepSeek-R1',
    });

    this.outputParser = new StringOutputParser();
  }

  // å…¨ç½‘AIå¯¹è¯
  async generateGlobalResponse(
    userMessage: string,
    messageHistory: any[] = [],
  ): Promise<string> {
    try {
      // æ„å»ºå¯¹è¯å†å²
      const messages = this.buildMessageHistory(messageHistory);
      messages.push(new HumanMessage(userMessage));

      // è°ƒç”¨æ¨¡å‹ç”Ÿæˆå›å¤
      const response = await this.globalChatModel.invoke(messages);
      return await this.outputParser.invoke(response);
    } catch (error) {
      this.logger.error(`Error in global AI response: ${error.message}`);
      throw error;
    }
  }

  // åŸºäºçŸ¥è¯†åº“çš„RAGå¯¹è¯
  async generateKnowledgeResponse(
    userMessage: string,
    knowledgeId: number,
    messageHistory: MessageEntiry[] = [],
  ): Promise<string> {
    const startTime = Date.now();
    console.log(
      `[${new Date().toISOString()}] ğŸ§  generateKnowledgeResponse å¼€å§‹æ‰§è¡Œ`,
    );
    console.log(
      `[${new Date().toISOString()}] ğŸ“ ç”¨æˆ·æ¶ˆæ¯: ${userMessage.substring(0, 100)}...`,
    );
    console.log(`[${new Date().toISOString()}] ğŸ·ï¸ çŸ¥è¯†åº“ID: ${knowledgeId}`);

    try {
      // 1. ä»å‘é‡æ•°æ®åº“æ£€ç´¢ç›¸å…³æ–‡æ¡£
      console.log(`[${new Date().toISOString()}] ğŸ” å¼€å§‹å‘é‡ç›¸ä¼¼åº¦æœç´¢`);
      const vectorSearchStart = Date.now();
      const relevantDocs = await this.vectorService.similaritySearch(
        knowledgeId,
        userMessage,
        5,
      );
      const vectorSearchTime = Date.now() - vectorSearchStart;
      console.log(
        `[${new Date().toISOString()}] âœ… å‘é‡æœç´¢å®Œæˆï¼Œè€—æ—¶: ${vectorSearchTime}msï¼Œæ‰¾åˆ° ${relevantDocs.length} ä¸ªç›¸å…³æ–‡æ¡£`,
      );

      // 2. æ„å»ºRAGæç¤ºè¯
      console.log(`[${new Date().toISOString()}] ğŸ“‹ å¼€å§‹æ„å»ºRAGä¸Šä¸‹æ–‡`);
      const contextBuildStart = Date.now();
      const context = relevantDocs.map((doc) => doc.content).join('\n\n');
      const contextLength = context.length;
      console.log(relevantDocs);
      const ragPrompt = ChatPromptTemplate.fromTemplate(`
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·åŸºäºä»¥ä¸‹æä¾›çš„çŸ¥è¯†åº“å†…å®¹æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚åœ¨å›ç­”é—®é¢˜æ—¶æŒ‡å‡ºå‚è€ƒäº†çŸ¥è¯†åº“ä¸­å“ªäº›å†…å®¹
å¦‚æœçŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·ã€‚

çŸ¥è¯†åº“å†…å®¹ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·åŸºäºä¸Šè¿°çŸ¥è¯†åº“å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ï¼š`);
      const contextBuildTime = Date.now() - contextBuildStart;
      console.log(
        `[${new Date().toISOString()}] âœ… RAGä¸Šä¸‹æ–‡æ„å»ºå®Œæˆï¼Œè€—æ—¶: ${contextBuildTime}msï¼Œä¸Šä¸‹æ–‡é•¿åº¦: ${contextLength} å­—ç¬¦`,
      );

      // 3. æ„å»ºæ¶ˆæ¯å†å²
      console.log(`[${new Date().toISOString()}] ğŸ“š å¼€å§‹æ„å»ºæ¶ˆæ¯å†å²`);
      const messageHistoryStart = Date.now();
      const messages = this.buildMessageHistory(messageHistory);
      const messageHistoryTime = Date.now() - messageHistoryStart;
      console.log(
        `[${new Date().toISOString()}] âœ… æ¶ˆæ¯å†å²æ„å»ºå®Œæˆï¼Œè€—æ—¶: ${messageHistoryTime}msï¼Œå†å²æ¶ˆæ¯æ•°: ${messageHistory.length}`,
      );

      // 4. æ·»åŠ RAGæç¤ºè¯å’Œç”¨æˆ·é—®é¢˜
      console.log(`[${new Date().toISOString()}] ğŸ”§ å¼€å§‹æ ¼å¼åŒ–æç¤ºè¯`);
      const promptFormatStart = Date.now();
      const formattedPrompt = await ragPrompt.format({
        context,
        question: userMessage,
      });
      const promptFormatTime = Date.now() - promptFormatStart;
      console.log(
        `[${new Date().toISOString()}] âœ… æç¤ºè¯æ ¼å¼åŒ–å®Œæˆï¼Œè€—æ—¶: ${promptFormatTime}msï¼Œæœ€ç»ˆæç¤ºè¯é•¿åº¦: ${formattedPrompt.length} å­—ç¬¦`,
      );

      messages.push(new HumanMessage(formattedPrompt));

      // 5. è°ƒç”¨æ¨¡å‹ç”Ÿæˆå›å¤
      console.log(`[${new Date().toISOString()}] ğŸ¤– å¼€å§‹è°ƒç”¨RAGæ¨¡å‹`);
      const modelInvokeStart = Date.now();
      const response = await this.ragChatModel.invoke(messages);
      const modelInvokeTime = Date.now() - modelInvokeStart;
      console.log(
        `[${new Date().toISOString()}] âœ… RAGæ¨¡å‹è°ƒç”¨å®Œæˆï¼Œè€—æ—¶: ${modelInvokeTime}ms`,
      );

      console.log(`[${new Date().toISOString()}] ğŸ”„ å¼€å§‹è§£æè¾“å‡º`);
      const parseStart = Date.now();
      const finalResponse = await this.outputParser.invoke(response);
      const parseTime = Date.now() - parseStart;
      const responseLength = finalResponse.length;
      console.log(
        `[${new Date().toISOString()}] âœ… è¾“å‡ºè§£æå®Œæˆï¼Œè€—æ—¶: ${parseTime}msï¼Œå“åº”é•¿åº¦: ${responseLength} å­—ç¬¦`,
      );

      const totalTime = Date.now() - startTime;
      console.log(
        `[${new Date().toISOString()}] ğŸ‰ generateKnowledgeResponse æ‰§è¡Œå®Œæˆ`,
      );
      console.log(`ğŸ“Š AIæœåŠ¡æ€§èƒ½ç»Ÿè®¡:`);
      console.log(
        `  - å‘é‡æœç´¢: ${vectorSearchTime}ms (${((vectorSearchTime / totalTime) * 100).toFixed(1)}%)`,
      );
      console.log(
        `  - ä¸Šä¸‹æ–‡æ„å»º: ${contextBuildTime}ms (${((contextBuildTime / totalTime) * 100).toFixed(1)}%)`,
      );
      console.log(
        `  - æ¶ˆæ¯å†å²æ„å»º: ${messageHistoryTime}ms (${((messageHistoryTime / totalTime) * 100).toFixed(1)}%)`,
      );
      console.log(
        `  - æç¤ºè¯æ ¼å¼åŒ–: ${promptFormatTime}ms (${((promptFormatTime / totalTime) * 100).toFixed(1)}%)`,
      );
      console.log(
        `  - æ¨¡å‹è°ƒç”¨: ${modelInvokeTime}ms (${((modelInvokeTime / totalTime) * 100).toFixed(1)}%)`,
      );
      console.log(
        `  - è¾“å‡ºè§£æ: ${parseTime}ms (${((parseTime / totalTime) * 100).toFixed(1)}%)`,
      );
      console.log(`  - æ€»è€—æ—¶: ${totalTime}ms`);
      console.log(`==========================================`);

      return finalResponse;
    } catch (error) {
      const errorTime = Date.now() - startTime;
      console.error(
        `[${new Date().toISOString()}] âŒ generateKnowledgeResponse æ‰§è¡Œå¤±è´¥ï¼Œè€—æ—¶: ${errorTime}ms`,
      );
      console.error(`âŒ é”™è¯¯è¯¦æƒ…: ${error.message}`);
      this.logger.error(`Error in knowledge AI response: ${error.message}`);
      throw error;
    }
  }

  // æ„å»ºæ¶ˆæ¯å†å²
  private buildMessageHistory(messageHistory: MessageEntiry[]) {
    const messages = [] as Message[];

    // æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
    messages.push(
      new SystemMessage('ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œè¯·å‹å¥½ã€å‡†ç¡®åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚'),
    );

    // æ·»åŠ å†å²æ¶ˆæ¯ï¼ˆæœ€è¿‘10æ¡ï¼‰
    const recentHistory = messageHistory.slice(-10);
    for (const msg of recentHistory) {
      if (msg.sender_type === 'user') {
        messages.push(new HumanMessage(msg.content));
      } else if (msg.sender_type === 'ai') {
        messages.push(new AIMessage(msg.content));
      }
    }

    return messages;
  }

  // å¤„ç†æ–‡ä»¶ä¸Šä¼ åˆ°å‘é‡æ•°æ®åº“
  async processFileForVector(
    knowledgeId: number,
    fileId: number,
    filePath: string, // æ”¹ä¸ºæ–‡ä»¶è·¯å¾„
    metadata: any = {},
  ) {
    return await this.vectorService.addDocument(
      knowledgeId,
      fileId,
      filePath,
      metadata,
    );
  }

  // æ·»åŠ è·å–æ–‡ä»¶ç±»å‹ä¿¡æ¯çš„æ–¹æ³•
  getFileTypeInfo(filePath: string) {
    return this.vectorService.getFileTypeInfo(filePath);
  }

  // ä»å‘é‡æ•°æ®åº“åˆ é™¤æ–‡ä»¶
  async removeFileFromVector(knowledgeId: number, fileId: number) {
    return await this.vectorService.removeDocument(knowledgeId, fileId);
  }

  // åˆ é™¤çŸ¥è¯†åº“å‘é‡æ•°æ®
  async deleteKnowledgeVectors(knowledgeId: number) {
    return await this.vectorService.deleteCollection(knowledgeId);
  }

  // åœ¨ AiService ä¸­æ–°å¢æµå¼å“åº”æ–¹æ³•

  // å…¨ç½‘æœç´¢æµå¼å“åº”
  async *generateGlobalStreamResponse(
    userMessage: string,
    messageHistory: any[] = [],
  ): AsyncGenerator<string, void, unknown> {
    try {
      console.log(`[${new Date().toISOString()}] ğŸŒ å¼€å§‹å…¨ç½‘æœç´¢æµå¼å“åº”`);

      const messages = this.buildMessageHistory(messageHistory);
      messages.push(new HumanMessage(userMessage));

      // ä½¿ç”¨æµå¼è°ƒç”¨
      const stream = await this.globalChatModel.stream(messages);

      for await (const chunk of stream) {
        if (chunk.content) {
          yield chunk.content as string;
        }
      }

      console.log(`[${new Date().toISOString()}] âœ… å…¨ç½‘æœç´¢æµå¼å“åº”å®Œæˆ`);
    } catch (error) {
      console.error(`å…¨ç½‘æœç´¢æµå¼å“åº”é”™è¯¯: ${error.message}`);
      throw error;
    }
  }

  // çŸ¥è¯†åº“RAGæµå¼å“åº”
  async *generateKnowledgeStreamResponse(
    userMessage: string,
    knowledgeId: number,
    messageHistory: any[] = [],
  ): AsyncGenerator<string, void, unknown> {
    try {
      console.log(`[${new Date().toISOString()}] ğŸ§  å¼€å§‹çŸ¥è¯†åº“RAGæµå¼å“åº”`);

      // 1. å‘é‡æœç´¢
      const vectorStart = Date.now();
      const relevantDocs = await this.vectorService.similaritySearch(
        knowledgeId,
        userMessage,
        5,
      );
      console.log(
        `[${new Date().toISOString()}] ğŸ“Š å‘é‡æœç´¢å®Œæˆï¼Œè€—æ—¶: ${Date.now() - vectorStart}ms`,
      );

      // 2. æ„å»ºRAGä¸Šä¸‹æ–‡
      const context = relevantDocs.map((doc) => doc.content).join('\n\n');
      const ragPrompt = ChatPromptTemplate.fromTemplate(`
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·åŸºäºä»¥ä¸‹æä¾›çš„çŸ¥è¯†åº“å†…å®¹æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
å¦‚æœçŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·ã€‚

çŸ¥è¯†åº“å†…å®¹ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·åŸºäºä¸Šè¿°çŸ¥è¯†åº“å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ï¼š`);

      // 3. æ„å»ºæ¶ˆæ¯å†å²
      const messages = this.buildMessageHistory(messageHistory);
      const formattedPrompt = await ragPrompt.format({
        context,
        question: userMessage,
      });
      messages.push(new HumanMessage(formattedPrompt));

      // 4. æµå¼è°ƒç”¨æ¨¡å‹
      const stream = await this.ragChatModel.stream(messages);

      for await (const chunk of stream) {
        if (chunk.content) {
          yield chunk.content as any;
        }
      }

      console.log(`[${new Date().toISOString()}] âœ… çŸ¥è¯†åº“RAGæµå¼å“åº”å®Œæˆ`);
    } catch (error) {
      console.error(`çŸ¥è¯†åº“RAGæµå¼å“åº”é”™è¯¯: ${error.message}`);
      throw error;
    }
  }
}
